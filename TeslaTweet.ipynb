{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdou19-97/TweetSentement/blob/main/TeslaTweet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyBXvWAIAkAp"
      },
      "outputs": [],
      "source": [
        "# !pip install Transformers \n",
        "# !pip install scipy\n",
        "import pandas as pd\n",
        "import tweepy\n",
        "from textblob import TextBlob\n",
        "from wordcloud import wordcloud\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CszS2hTOGDhf"
      },
      "outputs": [],
      "source": [
        "# from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
        "# from scipy.special import softmax\n",
        "# Load the CSV file into a pandas DataFrame\n",
        "df = pd.read_csv('/content/drive/MyDrive/TeslaStockTweet/stock_tweets.csv')\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove any rows with missing or invalid data\n",
        "df = df.dropna()\n",
        "# Remove any non-alphanumeric characters and convert to lowercase\n",
        "df['Tweet'] = df['Tweet'].apply(lambda x: re.sub(r'[^a-zA-Z0-9\\s]', '', x.lower()))\n",
        "# Tokenize the text into words\n",
        "df['tokens'] = df['Tweet'].apply(lambda x: word_tokenize(x))\n"
      ],
      "metadata": {
        "id": "1-i3ELBeMo8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "boEOSpfmgF9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the tweets by date\n",
        "daily_counts = df.groupby('Date').size().reset_index(name='counts')"
      ],
      "metadata": {
        "id": "EQH55uEQNX8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LU6NftzH2d7"
      },
      "outputs": [],
      "source": [
        "# Remove stop short words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "df['tokens'] = df['tokens'].apply(lambda x: [w for w in x if w not in stop_words and len(w) > 2])\n",
        "# Convert the tokens back to a string\n",
        "df['clean_text'] = df['tokens'].apply(lambda x: ' '.join(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "psvxIsFdgJgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample the dataset\n",
        "df = df.sample(frac=1, random_state=1)\n",
        "df.columns"
      ],
      "metadata": {
        "id": "DuL0obt79mrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIRMGAiq6kaO"
      },
      "outputs": [],
      "source": [
        "# Add columns for subjectivity and polarity\n",
        "# Polarity refers to whether the tweet is positive or negative \n",
        "# Subjectivity refers to personal opinion, feelings. etc...\n",
        "df['Subj'] = df['clean_text'].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
        "df['Polar'] = df['clean_text'].apply(lambda x: TextBlob(x).sentiment.polarity)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "jYpPOk_QQL48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3aRKY_dASNA"
      },
      "outputs": [],
      "source": [
        "# Plot the word cloud\n",
        "allwords = ' '.join([tweet for tweet in df['clean_text']])\n",
        "wordcloud = wordcloud.WordCloud(width=500, height=300, random_state=21, max_font_size=110).generate(allwords)\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyiZBjS1CTv9"
      },
      "outputs": [],
      "source": [
        "#create a function to compute negative neutral and positive analysis\n",
        "def getAnalysis(score):\n",
        "  if score < 0:\n",
        "    return -1\n",
        "  elif score > 0:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "#create new column called analysis and set it to polarity \n",
        "df['Score'] = df['Polar'].apply(getAnalysis)\n",
        "\n",
        "#show the dataframe\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnlPKmgVDu4s"
      },
      "outputs": [],
      "source": [
        "from numpy.ma import count\n",
        "#print all of the positive tweets\n",
        "#Print positive tweets\n",
        "# positive_tweets = df[df.Score == \"1\"]['clean_text']\n",
        "# for i, tweet in enumerate(positive_tweets):\n",
        "#     print(f\"{i+1}) {tweet}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Print positive tweets\n",
        "positive_tweets = df[df.Score == 1]['clean_text']\n",
        "positive = round((len(positive_tweets) / len(df)) * 100, 1)\n",
        "print(f\"Percentage of positive tweets: {positive}%\")"
      ],
      "metadata": {
        "id": "OQY4L-4rupGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J97gmyXKMjDB"
      },
      "outputs": [],
      "source": [
        "# Print negative tweets\n",
        "negative_tweets = df[df.Score == -1]['clean_text']\n",
        "n_negative = round((len(negative_tweets) / len(df)) * 100, 1)\n",
        "print(f\"Percentage of negative tweets: {n_negative}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neutral_tweets = df[df.Score == 0]['clean_text']\n",
        "neutral_tweets = round((len(neutral_tweets) / len(df)) * 100, 1)\n",
        "print(f\"Percentage of neutral tweets: {neutral_tweets}%\")"
      ],
      "metadata": {
        "id": "kaVYC7A-wncX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31ddf445-2021-4dee-e4a2-672c31d1d6b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of neutral tweets: 37.6%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#show the value counts\n",
        "df['Score'].value_counts()\n",
        "#Visualize the counts\n",
        "plt.title('Sentiment Analysis')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('count')\n",
        "df['Score'].value_counts().plot(kind='bar')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nLyRoJJbTgRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oiJDB83FxwoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the date column to a datetime object\n",
        "# df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
        "## Define a list of contextual words to filter out\n",
        "contextual_words = ['tsla','tesla','amzn','nio','elon musk','tsm','stock', 'stocks', 'market', 'trading', 'finance', 'investment', 'investing', 'portfolio', 'trade', 'shares', 'company', 'companies', 'investor']"
      ],
      "metadata": {
        "id": "v7Ake4e4Ueh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to filter out non-contextual words\n",
        "def filter_words(tokens):\n",
        "    filtered_tokens = [token for token in tokens if token.lower() not in contextual_words]\n",
        "    return filtered_tokens\n",
        "\n",
        "# Define a function to calculate the sentiment score for a list of tokens\n",
        "def get_sentiment_score(tokens):\n",
        "    sentiment_score = 0\n",
        "    for token in tokens:\n",
        "        blob = TextBlob(token)\n",
        "        sentiment_score += blob.sentiment.polarity\n",
        "    return sentiment_score\n"
      ],
      "metadata": {
        "id": "3CMYsJgPQl7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new column for the filtered tokens\n",
        "df['filtered_tokens'] = df['tokens'].apply(filter_words)\n",
        "\n",
        "# Calculate the sentiment score for each tweet\n",
        "df['sentiment_score'] = df['filtered_tokens'].apply(get_sentiment_score)\n",
        "\n",
        "# Group the tweets by date and calculate the mean sentiment score for each day\n",
        "daily_sentiment = df.groupby('Date')['sentiment_score'].mean().reset_index(name='sentiment_score')\n",
        "\n",
        "# Merge the daily counts and daily sentiment into a single dataframe\n",
        "daily_data = pd.merge(daily_counts, daily_sentiment, on='Date')"
      ],
      "metadata": {
        "id": "VVI584KuTinJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "kAColxApTE1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print positive tweets\n",
        "positive_tweets = df[df.Score == 1]['filtered_tokens']\n",
        "positive = round((len(positive_tweets) / len(df)) * 100, 1)\n",
        "print(f\"Percentage of positive tweets: {positive}%\")"
      ],
      "metadata": {
        "id": "_erHsLedeMYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print negative tweets\n",
        "negative_tweets = df[df.Score == -1]['filtered_tokens']\n",
        "n_negative = round((len(negative_tweets) / len(df)) * 100, 1)\n",
        "print(f\"Percentage of negative tweets: {n_negative}%\")"
      ],
      "metadata": {
        "id": "3txCBqGFe9OJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neutral_tweets = df[df.Score == 0]['filtered_tokens']\n",
        "neutral_tweets = round((len(neutral_tweets) / len(df)) * 100, 1)\n",
        "print(f\"Percentage of neutral tweets: {neutral_tweets}%\")"
      ],
      "metadata": {
        "id": "brrKwZQwfDjr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1DDANPRoBh4l0ptpo_SyKY77RFHslKQTa",
      "authorship_tag": "ABX9TyNHpuO4Vof6xUlLqXDnA0C3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}